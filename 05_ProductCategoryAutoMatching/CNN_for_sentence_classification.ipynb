{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import gluonnlp as nlp\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from pprint import pprint\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_name = ['itme_SEQ', 'category_SEQ', 'company_SEQ', 'price', 'item_name', 'brand_name', 'maker_name', 'cateL',\n",
    "            'cateM', 'cateS','cateD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./ProductCategoryAutoMatching/data_small/train.tsv', header=None, delimiter='\\t',names=col_name, index_col=None )\n",
    "train_data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_data = pd.read_csv('./ProductCategoryAutoMatching/data_small/valid.tsv', header=None, delimiter='\\t',names=col_name, index_col=None )\n",
    "valid_data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./ProductCategoryAutoMatching/data_small/test.tsv', header=None, delimiter='\\t',names=col_name, index_col=None )\n",
    "test_data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "# feature들 다 합침.\n",
    "ws_tok = WhitespaceTokenizer()\n",
    "\n",
    "def preprocessing(item_name, brand_name, maker_name, cateL, cateM, cateS, cateD):\n",
    "    if len(item_name) == 0: item_name = ''\n",
    "    elif len(brand_name) == 0: brand_name = ''\n",
    "    elif len(maker_name) == 0: maker_name = ''\n",
    "    elif len(cateL) == 0: cateL = ''\n",
    "    elif len(cateM) == 0: cateM = ''\n",
    "    elif len(cateS) == 0: cateS = ''\n",
    "    elif len(cateD) == 0: cateD = ''\n",
    "    \n",
    "    new_name = re.sub(\"[^가-힣]\", ' ', item_name+' '+brand_name+' '+maker_name+' '+cateL+' '+cateM\n",
    "                     +' '+cateS+' '+cateD)\n",
    "    new_name = list(set(ws_tok.tokenize(new_name)))\n",
    "    return new_name\n",
    "\n",
    "# def one_hot(dataset):\n",
    "#     indices = [0, 1, 2]\n",
    "# depth = 3\n",
    "# tf.one_hot(indices, depth)\n",
    "\n",
    "#      category_one_hot = tf.one_hot(dataset.category_SEQ, )\n",
    "    \n",
    "def feature_concat(dataset):\n",
    "    features = []\n",
    "    item = dataset.item_name\n",
    "    brand = dataset.brand_name\n",
    "    maker = dataset.maker_name\n",
    "    cateL = dataset.cateL\n",
    "    cateM = dataset.cateM\n",
    "    cateS = dataset.cateS\n",
    "    cateD = dataset.cateD\n",
    "\n",
    "    for i in range(1, len(dataset)):\n",
    "        features.append(preprocessing(item[i], brand[i], maker[i], cateL[i], cateM[i], cateS[i], cateD[i]))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train, validation, test set \n",
    "tr_data = feature_concat(train_data) \n",
    "val_data = feature_concat(valid_data)\n",
    "tst_data = feature_concat(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building vocabulary and connecting vocabulary with fasttext embedding  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vocab using gluonnlp, fasttext \n",
    "counter = nlp.data.count_tokens(itertools.chain.from_iterable([c for c in tr_data]))\n",
    "vocab = nlp.Vocab(counter,bos_token=None, eos_token=None, min_freq=1)\n",
    "\n",
    "# Loading fasttext embedding \n",
    "fasttext_simple = nlp.embedding.create('fasttext', source='wiki.ko')\n",
    "# vocab에 fasttest붙여줌\n",
    "vocab.set_embedding(fasttext_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed = vocab.embedding.idx_to_vec.asnumpy()\n",
    "initial_shape = embed.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding of X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding func\n"
     ]
    }
   ],
   "source": [
    "def embedding(dataset):\n",
    "    #vocab.embedding.idx_to_vec\n",
    "    token2idx = list(map(lambda sen: [vocab.token_to_idx[token] for token in sen], dataset))\n",
    "    token2idx = pad_sequences(sequences=token2idx, maxlen=300, padding='post', truncating='post', value=1)\n",
    "    return token2idx #type: np.ndarray\n",
    "\n",
    "print('embedding func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = embedding(tr_data)\n",
    "y_tr = list(elm-1 for elm in train_data.category_SEQ[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val = embedding(val_data)\n",
    "y_val = list(elm-1 for elm in valid_data.category_SEQ[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tst = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tst = embedding(tst_data)\n",
    "y_tst = list(elm-1 for elm in test_data.category_SEQ[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21718, 300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MorphConv:\n",
    "    def __init__(self, X, y, n_of_classes, embedding):\n",
    "        \n",
    "        with tf.variable_scope('input_layer'):\n",
    "            self.__X = X\n",
    "            self.__y = y\n",
    "            self.is_training = tf.placeholder(dtype = tf.bool)\n",
    "        \n",
    "        with tf.variable_scope('embedding_layer'): # Mulit-channel 구현(Static-channel, Non-static channel)\n",
    "            static_embed = tf.get_variable(name = 'static', initializer = embedding,\n",
    "                                           trainable = False) # static이라서 word vector training 안시킴 \n",
    "            non_static_embed = tf.get_variable(name = 'non_static', initializer = embedding,\n",
    "                                               trainable = True) # non-static이라서 word vector training 시킴 \n",
    "#             print(static_embed)\n",
    "            static_batch = tf.nn.embedding_lookup(params = static_embed, ids = self.__X)\n",
    "            non_static_batch = tf.nn.embedding_lookup(params = non_static_embed, ids = self.__X)\n",
    "            \n",
    "        with tf.variable_scope('convoluion_layer'):\n",
    "            with tf.variable_scope('tri_gram'): #token을 3개씩 봄\n",
    "                \n",
    "                tri_gram = keras.layers.Conv1D(filters = 100, kernel_size = 3, \n",
    "                                               activation = keras.activations.relu,\n",
    "                                               kernel_initializer = 'he_uniform', padding = 'valid')\n",
    "                static_3 = tri_gram(static_batch)\n",
    "                non_static_3 = tri_gram(non_static_batch)\n",
    "            \n",
    "            with tf.variable_scope('tetra_gram'): #token을 4개씩 봄\n",
    "                tetra_gram = keras.layers.Conv1D(filters = 100, kernel_size = 4,\n",
    "                                                 activation = keras.activations.relu,\n",
    "                                                 kernel_initializer = 'he_uniform', padding = 'valid')\n",
    "                \n",
    "                static_4 = tetra_gram(static_batch)\n",
    "                non_static_4 = tetra_gram(non_static_batch)\n",
    "            \n",
    "            with tf.variable_scope('penta_gram'): #token을 5개씩 봄\n",
    "                penta_gram = keras.layers.Conv1D(filters = 100, kernel_size = 5,\n",
    "                                                 activation = keras.activations.relu,\n",
    "                                                 kernel_initializer = 'he_uniform', padding = 'valid')\n",
    "                \n",
    "                static_5 = penta_gram(static_batch)\n",
    "                non_static_5 = penta_gram(non_static_batch)\n",
    "            \n",
    "            # Max over time pooling\n",
    "            fmap_3 = tf.reduce_max(static_3 + non_static_3, axis = 1)\n",
    "            fmap_4 = tf.reduce_max(static_4 + non_static_4, axis = 1)\n",
    "            fmap_5 = tf.reduce_max(static_5 + non_static_5, axis = 1)\n",
    "            \n",
    "        with tf.variable_scope('output_layer'):\n",
    "            flattened = tf.concat([fmap_3, fmap_4, fmap_5], axis = -1)\n",
    "            score = keras.layers.Dense(units = n_of_classes,\n",
    "                                       kernel_regularizer = keras.regularizers.l2(.7))(flattened)\n",
    "            \n",
    "            self.__score = keras.layers.Dropout(rate = .5)(score, training = self.is_training)\n",
    "\n",
    "        with tf.variable_scope('loss'):\n",
    "            ce_loss = tf.losses.sparse_softmax_cross_entropy(labels = self.__y, logits = self.__score)\n",
    "            reg_term = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "            self.total_loss = ce_loss + reg_term\n",
    "        \n",
    "        with tf.variable_scope('prediction'):\n",
    "            self.prediction = tf.argmax(self.__score, axis = -1)\n",
    "        \n",
    "    # predict instance method for small dataset\n",
    "    \n",
    "    def predict(self, sess, x_data, is_training = False):\n",
    "        feed_prediction = {self.__X : x_data, self.is_training : is_training}\n",
    "        return sess.run(self.prediction, feed_dict = feed_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameter\n",
    "lr = .003\n",
    "epochs = 5\n",
    "batch_size = 500\n",
    "total_step = int(X_tr.shape[0] / batch_size)\n",
    "print(total_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((X_tr, y_tr))\n",
    "tr_dataset = tr_dataset.shuffle(buffer_size = 1000000)\n",
    "tr_dataset = tr_dataset.batch(batch_size = batch_size)\n",
    "tr_iterator = tr_dataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# val\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size = batch_size)\n",
    "val_iterator = val_dataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# anonymous iterator\n",
    "handle = tf.placeholder(dtype = tf.string)\n",
    "iterator = tf.data.Iterator.from_string_handle(string_handle = handle,\n",
    "                                               output_types = tr_iterator.output_types,\n",
    "                                               output_shapes = tr_iterator.output_shapes)\n",
    "x_data, y_data = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_conv = MorphConv(X = x_data, y = y_data, n_of_classes = 11,\n",
    "                       embedding = vocab.embedding.idx_to_vec.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training op\n",
    "opt = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "training_op = opt.minimize(loss = morph_conv.total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tr_handle, val_handle = sess.run(fetches = [tr_iterator.string_handle(), val_iterator.string_handle()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [03:30<14:01, 210.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   1, tr_loss : 1.743, val_loss : 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [06:59<10:30, 210.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   2, tr_loss : 1.434, val_loss : 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [10:30<07:00, 210.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   3, tr_loss : 1.326, val_loss : 0.770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [14:01<03:30, 210.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   4, tr_loss : 1.256, val_loss : 0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 5/5 [17:31<00:00, 210.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   5, tr_loss : 1.213, val_loss : 0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tr_loss_hist = []\n",
    "val_loss_hist = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    avg_tr_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    tr_step = 0\n",
    "    val_step = 0\n",
    "\n",
    "    # for mini-batch training\n",
    "    sess.run(tr_iterator.initializer)    \n",
    "    try:\n",
    "        \n",
    "        while True:\n",
    "            _, tr_loss = sess.run(fetches = [training_op, morph_conv.total_loss],\n",
    "                                             feed_dict = {handle : tr_handle, morph_conv.is_training : True})\n",
    "            avg_tr_loss += tr_loss\n",
    "            tr_step += 1\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    # for validation\n",
    "    sess.run(val_iterator.initializer)\n",
    "    try:\n",
    "        while True:\n",
    "            val_loss = sess.run(fetches = morph_conv.total_loss,\n",
    "                                feed_dict = {handle : val_handle, morph_conv.is_training : False})\n",
    "            avg_val_loss += val_loss\n",
    "            val_step += 1\n",
    "    \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    avg_tr_loss /= tr_step\n",
    "    avg_val_loss /= val_step\n",
    "    tr_loss_hist.append(avg_tr_loss)\n",
    "    val_loss_hist.append(avg_val_loss)\n",
    "    \n",
    "    print('epoch : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(epoch + 1, avg_tr_loss, avg_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_dataset = tf.data.Dataset.from_tensor_slices((X_tst, y_tst))\n",
    "tst_dataset = tst_dataset.batch(batch_size = batch_size)\n",
    "tst_iterator = tst_dataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_handle = sess.run(tst_iterator.string_handle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tst_hat = np.array([])\n",
    "\n",
    "sess.run(tst_iterator.initializer)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        y_tst_tmp = sess.run(morph_conv.prediction,\n",
    "                            feed_dict = {handle : tst_handle,\n",
    "                                         morph_conv.is_training : False})\n",
    "        y_tst_hat= np.append(y_tst_hat,y_tst_tmp)\n",
    "\n",
    "except tf.errors.OutOfRangeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 74.22%\n"
     ]
    }
   ],
   "source": [
    "print('test acc : {:.2%}'.format(np.mean(y_tst_hat == np.array(y_tst))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f06dc722b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist, label = 'train')\n",
    "plt.plot(val_loss_hist, label = 'validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model\n",
    "- saver.save(sess=sess, save_path=path) \n",
    "- 모델 인스턴스 생성(weight x)\n",
    "- saver.restore(sess, save_path) --> (weight o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(var_list=val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./cnn_model_9/'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess= sess, save_path = './cnn_model_9/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data_infer = tf.placeholder(dtype = tf.int32, shape = [None, 300]) # 300은 sequence의 max_length\n",
    "y_data_infer = tf.placeholder(dtype = tf.int32, shape = [None]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = np.zeros(shape = [initial_shape,300], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_conv_infer = MorphConv(X = x_data_infer, y = y_data_infer, n_of_classes = 11,\n",
    "                             embedding = initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./cnn_model_9/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./cnn_model_9/\n"
     ]
    }
   ],
   "source": [
    "#restore model \n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess = sess , save_path =  './cnn_model_9/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tst_hat = morph_conv_infer.predict(sess = sess, x_data = X_tst[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 5, 5, 5, 2, 5, 1, 4, 7])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tst_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tst[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
