{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_MLP.ipynb의 사본",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "lunw6QAeWRV5",
        "_RKTk9h3WyL0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "zKFS5GGRct9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "372a2067-1bbb-48b7-f7fe-6c39614bca13"
      },
      "cell_type": "code",
      "source": [
        "# Hello World!\n",
        "print('Hello World')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello World\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kdQ-GsBQc2V5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Colab 에서 pyTorch 를 사용하기 위해 설치하는 과정입니다."
      ]
    },
    {
      "metadata": {
        "id": "Pbwu6S4wOxd4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "accelerator = 'cu80' if os.path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S06EEKiGdIu5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### pyTorch 를 비롯해 오늘 실습에 필요한 파이썬 라이브러리를 읽어들입니다."
      ]
    },
    {
      "metadata": {
        "id": "-2LhJhxtc0Cm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn #\n",
        "import torch.nn.functional as F #\n",
        "import torchvision # 이미지 관련 처리, Pretrained Model 관련된 Package 입니다. \n",
        "import torchvision.datasets as vision_dsets\n",
        "import torchvision.transforms as T # 이미지 처리 (Vison) 관련된 transformation이 정의 되어 있습니다.\n",
        "import torch.optim as optim # pytorch 에서 정의한 수 많은 optimization function 들이 들어 있습니다.\n",
        "from torch.utils import data\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # 시각화를 위한 패키지입니다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OMUvi23EdWvr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST Feed-Forward Neural Network for a classification"
      ]
    },
    {
      "metadata": {
        "id": "paXurbj1dklQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Loader 불러오기\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- 물음표 2곳 채우기"
      ]
    },
    {
      "metadata": {
        "id": "HsUDRfce3AAQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_train = vision_dsets.MNIST(root = './',  #root 는 데이터의 저장 위치 입니다. \n",
        "\t\t\t\t\t\t\t\t\ttrain = True, #Train 은 이 데이터가 train 데이터인지 아닌지에 대한 정보입니다. \n",
        "\t\t\t\t\t\t\t\t\ttransform = T.ToTensor(), # 얻어낸 데이터를 pytorch가 계산 할 수 있는 Tensor 로 변환해 줍니다. \n",
        "\t\t\t\t\t\t\t\t\tdownload = True)  # 데이터를 다운로드 할지 여부를 물어봅니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p_FGfwh53IJT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "c8ae6303-fbfa-4dd1-f453-7b8ae5eaa5d2"
      },
      "cell_type": "code",
      "source": [
        "print(mnist_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Split: train\n",
            "    Root Location: ./\n",
            "    Transforms (if any): ToTensor()\n",
            "    Target Transforms (if any): None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rvKu7wD3c0I8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def MNIST_DATA(root='./', train=True, transforms=None, download =True,batch_size=32, num_worker=1):\n",
        "\n",
        "\tprint (\"[+] Get the MNIST DATA\")\n",
        "\t\"\"\"\n",
        "  \ttorchvision.dataset 에는 우리가 많이 사용하는 데이터들을 쉽게 사용할 수 있도록 되어 있습니다. \n",
        "  \tMachine Learning 에서 Hello world 라고 불리는 Mnist 데이터를 사용해 보겠습니다. \n",
        "  \n",
        "\t\"\"\"\n",
        "\tmnist_train = vision_dsets.MNIST(root = root,  #root 는 데이터의 저장 위치 입니다. \n",
        "\t\t\t\t\t\t\t\t\ttrain = True, #Train 은 이 데이터가 train 데이터인지 아닌지에 대한 정보입니다. \n",
        "\t\t\t\t\t\t\t\t\ttransform = T.ToTensor(), # 얻어낸 데이터를 pytorch가 계산 할 수 있는 Tensor 로 변환해 줍니다. \n",
        "\t\t\t\t\t\t\t\t\tdownload = True)  # 데이터를 다운로드 할지 여부를 물어봅니다. \n",
        "\tmnist_test = vision_dsets.MNIST(root = root,\n",
        "\t\t\t\t\t\t\t\t\ttrain = False,  # Test Data를 가져오기에 Train =False 를 줘야 합니다. \n",
        "\t\t\t\t\t\t\t\t\ttransform = T.ToTensor(),\n",
        "\t\t\t\t\t\t\t\t\tdownload = True)\n",
        "\t\"\"\"\n",
        "  \tData Loader 는 데이터와 batch size의 정보를 바탕으로 매 iteration 마다 주어진 데이터를 원하는 batch size 만큼 반환해주는 iterator입니다. \n",
        "  \t* Practical Guide : Batch size 는 어느정도가 좋나요? -- 클 수록 좋다는 소리가 있습니다. 하지만 gpu memeory 사이즈 한계에 의해 기본적으로 batch size 가 \n",
        "  \t커질 수록 학습에 사용되는 gpu memory 사이즈가 큽니다. (Activation map을 저장해야 하기 때문입니다.) 기본적으로 2의 배수로 저장하는 것이 좋습니다.(Bit size 관련) \n",
        "  \n",
        "\t\"\"\"\n",
        "\ttrainDataLoader = data.DataLoader(dataset = mnist_train,  # DataSet은 어떤 Data를 제공해 줄지에 대한 정보입니다. 여기서는 Training DATA를 제공합니다. \n",
        "\t\t\t\t\t\t\t\t\tbatch_size = batch_size, # batch size 정보를 꼭 줘야 합니다. 한 Batch 당 몇 개의 Data 를 제공할지에 대한 정보입니다. \n",
        "\t\t\t\t\t\t\t\t\tshuffle = True, # Training의 경우 Shuffling 을 해주는 것이 성능에 지대한 영향을 끼칩니다. 꼭 True 를 줘야 합니다. \n",
        "\t\t\t\t\t\t\t\t\tnum_workers = 1) # num worker의 경우 데이터를 로드하는데 worker를 얼마나 추가하겠는가에 대한 정보입니다. \n",
        "\n",
        "\ttestDataLoader = data.DataLoader(dataset = mnist_test, # Test Data Loader 이므로 Test Data를 인자로 전달해줍니다.\n",
        "\t\t\t\t\t\t\t\t\tbatch_size = batch_size, # 마찬가지로 Batch size 를 넣어줍니다. \n",
        "\t\t\t\t\t\t\t\t\tshuffle = False, # shuffling 이 굳이 필요하지 않으므로 false를 줍니다. \n",
        "\t\t\t\t\t\t\t\t\tnum_workers = 1) #\n",
        "\tprint (\"[+] Finished loading data & Preprocessing\")\n",
        "\treturn mnist_train,mnist_test,trainDataLoader,testDataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zKkg5jcoc0NG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "8ba1843f-57b0-4e64-ea5a-b579da473e5e"
      },
      "cell_type": "code",
      "source": [
        "trainDset,testDset,trainDataLoader,testDataLoader= MNIST_DATA(batch_size = 32)  # Data Loader 를 불러 옵니다. \n",
        "print('[info] # of train batch : ', len(trainDataLoader)) # 60000개 이미지\n",
        "print('[info] # of test batch : ', len(testDataLoader)) # 10016개 이미지\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' # pytorch0.4.0 이상 버젼에서 gpu 설정하는 방식, tensor.to(device) 이런식으로 사용"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] Get the MNIST DATA\n",
            "[+] Finished loading data & Preprocessing\n",
            "[info] # of train batch :  1875\n",
            "[info] # of test batch :  313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "06PcsZV52RLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "95b96627-64f5-4457-a9a2-6443e6788b75"
      },
      "cell_type": "code",
      "source": [
        "dir(trainDataLoader.dataset.train_data.shaep)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__add__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_check_exists',\n",
              " 'download',\n",
              " 'processed_folder',\n",
              " 'raw_folder',\n",
              " 'root',\n",
              " 'target_transform',\n",
              " 'test_file',\n",
              " 'train',\n",
              " 'train_data',\n",
              " 'train_labels',\n",
              " 'training_file',\n",
              " 'transform',\n",
              " 'urls']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "88skWwfT3jDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9515bb62-b72c-48dd-f548-5fdc18408657"
      },
      "cell_type": "code",
      "source": [
        "print(trainDataLoader.dataset.train_data.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cchknkpD3pFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "36763db1-33a6-4179-ff23-0fc1927cbb37"
      },
      "cell_type": "code",
      "source": [
        "type(trainDset.train_labels)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "ggrUx5SxD6Hd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1e31f27c-9c1f-4d52-995d-6a9348ce07ce"
      },
      "cell_type": "code",
      "source": [
        "type(trainDset)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.MNIST"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "9BaMGXxu32xJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0bd86c8d-62ce-4eaa-c594-0e3e985d8a58"
      },
      "cell_type": "code",
      "source": [
        "trainDset.info()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-4ed1fd126405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainDset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'MNIST' object has no attribute 'info'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "V9eHg4ia5qtQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "79167654-7444-4748-c647-a92adb7c705f"
      },
      "cell_type": "code",
      "source": [
        "def showImages(image, row):\n",
        "  \n",
        "  for _ in range(row):  \n",
        "  \n",
        "    idx = np.random.choice(32, 6)     # 0 ~ 31 의 정수 중 6 개를 임의로 선택\n",
        "    images =image.numpy()[idx]         # 선택된 index 에 해당하는 이미지를 가져옴\n",
        "    \n",
        "    plt.figure(figsize = (15, 90))     # 세로 길이 15, 가로 길이 15 * 6 의 화면 생성\n",
        "    \n",
        "    for i in range(161, 167):    \n",
        "    \n",
        "      plt.subplot(i)\n",
        "      plt.imshow(images[i - 161])\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])    \n",
        "    \n",
        "    plt.show()  \n",
        "\n",
        "for i, (image, labels) in enumerate(trainDataLoader): \n",
        "  \n",
        "  showImages(image.squeeze(), 3)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAACFCAYAAAC+N6IzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6e84efedd8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAACFCAYAAAC+N6IzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6e84bb2f60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAACFCAYAAAC+N6IzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAMiimAAAAMvwHVlyoqazl9OkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6e84bd96a0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "DZ5s8ItMgqke",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Function"
      ]
    },
    {
      "metadata": {
        "id": "XumKRGFZc0PV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_network(net,optimizer,trainloader):\n",
        "  for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "      running_loss = 0.0 # running loss를 저장하기 위한 변수입니다. \n",
        "      for i, data in enumerate(trainloader): # 한 Epoch 만큼 돕니다. 매 iteration 마다 정해진 Batch size 만큼 데이터를 뱉습니다. \n",
        "          # get the inputs\n",
        "          inputs, labels = data # DataLoader iterator의 반환 값은 input_data 와 labels의 튜플 형식입니다. \n",
        "          inputs = inputs.to(device) # Pytorch에서 nn.Module 에 넣어 Backprop을 계산 하기 위해서는 gpu 연동을 이와 같이 해줘야 합니다.\n",
        "          labels = labels.to(device)\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()    #  현재 기존의 backprop을 계산하기 위해서 저장했던 activation buffer 를 비웁니다. Q) 이걸 안 한다면? --> activation memory 가 터진다. \n",
        "                                   # forward 했을 떄 5000이 나오고, 안비워준다면 backpropagation 할때 5000더 추가되서 메모리에 부하\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = net(inputs) # input 을 넣은 위 network 로 부터 output 을 얻어냅니다. \n",
        "          loss = criterion(outputs, labels) # loss fucntion에 주어진 target과 output 의 score를 계산하여 반환합니다. \n",
        "          loss.backward() # * Scalar Loss value를 Backward() 해주게 되면 주어진 loss값을 바탕으로 backpropagation이 진행됩니다. \n",
        "          optimizer.step() # 계산된 Backprop 을 바탕으로 optimizer가 gradient descenting 을 수행합니다. \n",
        "\n",
        "          # print statistics\n",
        "          running_loss += loss.data[0]\n",
        "          if (i+1) % 500 == 0:    # print every 500 mini-batches\n",
        "              print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 500))\n",
        "              running_loss = 0.0\n",
        "\n",
        "  print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kCaC-wvJjUvT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test Function"
      ]
    },
    {
      "metadata": {
        "id": "Cwyd_W0qc0TH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(model,test_loader):\n",
        "  model.eval() # Eval Mode 왜 해야 할까요?  --> nn.Dropout BatchNorm 등의 Regularization 들이 test 모드로 들어가게 되기 때문입니다. \n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for data, target in test_loader:\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)  # 기존의 train function의 data 처리부분과 같습니다.  \n",
        "    output = model(data) \n",
        "    pred = output.max(1, keepdim=True)[1] # get the index of the max \n",
        "    correct += pred.eq(target.view_as(pred)).sum().data[0] # 정답 데이터의 갯수를 반환합니다. \n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print('\\nTest set:  Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "      correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XUK4Q1VJnbM7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network  + Activation Function"
      ]
    },
    {
      "metadata": {
        "id": "3u2nEyN0nitN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (1)\n",
        "특징 : 2개의 Layer를 가지는 Neural Network \n",
        "<구성>  \n",
        "Layer 1 - input:28*28 , output : 30 + Activation Fucntion - Sigmoid \n",
        "\n",
        "Layer 2 - input: 30 output:10\n",
        "\n",
        "Cross Entropy Loss  + SGD optimizer\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "물음표 1곳 채우기"
      ]
    },
    {
      "metadata": {
        "id": "R4TArcnmc0WT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__() # nn.Module 생성자 호출이 왜 필요할까요? nn.Module 을 상속받아서 부모의 메소드를 쓰기 위해서 상속 \n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc0 = nn.Linear(28*28,30)\n",
        "        self.fc1 = nn.Linear(30, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,28*28) # x.view함수는 주어진 인자의 크기로 해당 데이터의 크기를 반환합니다. 즉, (Batch_size,28,28) --> (Batch_size,28*28)로 변환합니다.\n",
        "        x = F.sigmoid(self.fc0(x)) # 28*28 -> 30 -> Activation function 을 수행합니다.\n",
        "        # linear layer 2ro --> linear layer 로 한개로 퉁처짐\n",
        "        # 따라서 non-linear 하게 하기 위해서 activation 함수를 써준다. \n",
        "        x = self.fc1(x)  # 30 -> 10 으로 10개의 Class에 대한 logit 값을 호출합니다. \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yoMSG1Ptnx90",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimizer \n",
        "Optimizer 의 경우 기본적으로 torch.optim 안에 존재합니다. 다양한 optimziers 가 정의되어 있습니다. \n",
        "\n",
        "기본적으로 다음과 같은 구성을 따릅니다. optim.{Optimzier 이름}({Network Parameters},lr ={learning rate })"
      ]
    },
    {
      "metadata": {
        "id": "cAIU84RmnyGi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_net = MNIST_Net().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.SGD(mnist_net.parameters(), lr=0.001) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lt_5iIICOomb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "b2b93bce-8e55-40b8-b70d-5e8379149cac"
      },
      "cell_type": "code",
      "source": [
        "train_network(mnist_net,optimizer,trainDataLoader) # 4 Epoch 정도 학습을 진행해봅니다. "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.311\n",
            "[1,  1000] loss: 2.294\n",
            "[1,  1500] loss: 2.279\n",
            "[2,   500] loss: 2.258\n",
            "[2,  1000] loss: 2.247\n",
            "[2,  1500] loss: 2.236\n",
            "[3,   500] loss: 2.216\n",
            "[3,  1000] loss: 2.203\n",
            "[3,  1500] loss: 2.189\n",
            "[4,   500] loss: 2.165\n",
            "[4,  1000] loss: 2.148\n",
            "[4,  1500] loss: 2.135\n",
            "[5,   500] loss: 2.101\n",
            "[5,  1000] loss: 2.084\n",
            "[5,  1500] loss: 2.065\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GHg1eIj3oFyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "a4dbc3b3-40b1-4946-9cb1-7a85288543f7"
      },
      "cell_type": "code",
      "source": [
        "test(mnist_net,testDataLoader) # Test 정확도를 출력해 봅니다. "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 6205/10000 (62%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zzbQfuLBBjAV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (2)\n",
        "특징 : 2개의 Layer를 가지는 Neural Network \n",
        "<구성>  \n",
        "Layer 1 - input:28*28 , output : 30 + Activation Fucntion - tanh \n",
        "\n",
        "Layer 2 - input: 30 output:10\n",
        "\n",
        "Cross Entropy Loss  + SGD optimizer "
      ]
    },
    {
      "metadata": {
        "id": "mR1SP6mB_LYE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc0 = nn.Linear(28*28,30)\n",
        "        self.fc1 = nn.Linear(30, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,28*28) # x.view함수는 주어진 인자의 크기로 해당 데이터의 크기를 반환합니다. 즉, (Batch_size,28,28) --> (Batch_size,28*28)로 변환합니다.\n",
        "        x = F.tanh(self.fc0(x)) # 28*28 -> 30 -> Activation function 을 수행합니다.\n",
        "        x = self.fc1(x)  # 30 -> 10 으로 10개의 Class에 대한 logit 값을 호출합니다. \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_h1A0xhCYxN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_net = MNIST_Net().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.SGD(mnist_net.parameters(), lr=0.001) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5UW3qPh5CeX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "81f9fcb0-8d49-4728-a012-c00d165eee66"
      },
      "cell_type": "code",
      "source": [
        "train_network(mnist_net,optimizer,trainDataLoader)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.222\n",
            "[1,  1000] loss: 2.068\n",
            "[1,  1500] loss: 1.922\n",
            "[2,   500] loss: 1.682\n",
            "[2,  1000] loss: 1.553\n",
            "[2,  1500] loss: 1.452\n",
            "[3,   500] loss: 1.275\n",
            "[3,  1000] loss: 1.189\n",
            "[3,  1500] loss: 1.123\n",
            "[4,   500] loss: 1.004\n",
            "[4,  1000] loss: 0.965\n",
            "[4,  1500] loss: 0.918\n",
            "[5,   500] loss: 0.845\n",
            "[5,  1000] loss: 0.820\n",
            "[5,  1500] loss: 0.779\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AiBv0wY8ClIs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "d0188ba4-6618-451b-d33e-bafb04b4ee81"
      },
      "cell_type": "code",
      "source": [
        "test(mnist_net,testDataLoader)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 8416/10000 (84%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YodiGI1lFSbh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![대체 텍스트](https://taewanmerepo.github.io/2017/12/tanh/010.jpg)\n",
        "![대체 텍스트](https://taewanmerepo.github.io/2017/12/tanh/020.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "d8aBndm2F0WF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (3)\n",
        "특징 : 2개의 Layer를 가지는 Neural Network \n",
        "<구성>  \n",
        "Layer 1 - input:28*28 , output : 30 + Activation Fucntion - Relu\n",
        "\n",
        "Layer 2 - input: 30 output:10\n",
        "\n",
        "Cross Entropy Loss  + SGD optimizer \n"
      ]
    },
    {
      "metadata": {
        "id": "FYL55HO8Fza-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc0 = nn.Linear(28*28,30)\n",
        "        self.fc1 = nn.Linear(30, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = x.view(-1,28*28)\n",
        "        x = F.relu(self.fc0(x))\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wPWHit95F6zX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_net = MNIST_Net().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.SGD(mnist_net.parameters(), lr=0.001) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "njHEPR7tF68C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "1ea91fb6-8c17-44d9-82e9-f750a611b187"
      },
      "cell_type": "code",
      "source": [
        "train_network(mnist_net,optimizer,trainDataLoader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.281\n",
            "[1,  1000] loss: 2.199\n",
            "[1,  1500] loss: 2.104\n",
            "[2,   500] loss: 1.899\n",
            "[2,  1000] loss: 1.758\n",
            "[2,  1500] loss: 1.605\n",
            "[3,   500] loss: 1.358\n",
            "[3,  1000] loss: 1.224\n",
            "[3,  1500] loss: 1.104\n",
            "[4,   500] loss: 0.961\n",
            "[4,  1000] loss: 0.884\n",
            "[4,  1500] loss: 0.833\n",
            "[5,   500] loss: 0.761\n",
            "[5,  1000] loss: 0.713\n",
            "[5,  1500] loss: 0.679\n",
            "[6,   500] loss: 0.629\n",
            "[6,  1000] loss: 0.617\n",
            "[6,  1500] loss: 0.602\n",
            "[7,   500] loss: 0.563\n",
            "[7,  1000] loss: 0.544\n",
            "[7,  1500] loss: 0.541\n",
            "[8,   500] loss: 0.521\n",
            "[8,  1000] loss: 0.500\n",
            "[8,  1500] loss: 0.498\n",
            "[9,   500] loss: 0.488\n",
            "[9,  1000] loss: 0.468\n",
            "[9,  1500] loss: 0.463\n",
            "[10,   500] loss: 0.455\n",
            "[10,  1000] loss: 0.449\n",
            "[10,  1500] loss: 0.434\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MJAGtHFbF_Yy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ed1b86d9-b461-44ee-d067-fa0466aa5d91"
      },
      "cell_type": "code",
      "source": [
        "test(mnist_net,testDataLoader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 8927/10000 (89%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8htgRteuG__I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![대체 텍스트](https://cdn-images-1.medium.com/max/1600/1*g0yxlK8kEBw8uA1f82XQdA.png)"
      ]
    },
    {
      "metadata": {
        "id": "jh8oLOl9G_Ao",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (4) \n",
        "특징 : 3개의 Layer를 가지는 Neural Network \n",
        "<구성>  \n",
        "Activation Fucntion - sigmoid \n",
        "\n",
        "Layer 1 - input:28*28 , output : 40\n",
        "\n",
        "Layer 2 - input: 40 output: 30\n",
        "\n",
        "Layer 3 - input: 30 output : 10\n",
        "\n",
        "Cross Entropy Loss  + SGD optimizer "
      ]
    },
    {
      "metadata": {
        "id": "AtuqhspQHSNM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        self.fc0 = nn.Linear(28*28,40) # Layer 1\n",
        "        self.fc1 = nn.Linear(40, 30) # Layer 2\n",
        "        self.fc2 = nn.Linear(30, 10) # Layer 3\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "        x = x.view(-1,28*28)\n",
        "        x = F.sigmoid(self.fc0(x))\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oNG23xqiHSWB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_net = MNIST_Net().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.SGD(mnist_net.parameters(), lr=0.001) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RAKB5VlpHSa7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "700b20f6-2b45-4500-adba-b50d5fd7c9ee"
      },
      "cell_type": "code",
      "source": [
        "# 활성화 함수가 sigmoid 두개로 쌓아서 gradient descent 를 할때 값이 너무 작아짐. 즉 갱신하지를 못함 . (local 에 갇힘?)\n",
        "train_network(mnist_net,optimizer,trainDataLoader)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.320\n",
            "[1,  1000] loss: 2.310\n",
            "[1,  1500] loss: 2.304\n",
            "[2,   500] loss: 2.301\n",
            "[2,  1000] loss: 2.300\n",
            "[2,  1500] loss: 2.300\n",
            "[3,   500] loss: 2.300\n",
            "[3,  1000] loss: 2.299\n",
            "[3,  1500] loss: 2.298\n",
            "[4,   500] loss: 2.299\n",
            "[4,  1000] loss: 2.298\n",
            "[4,  1500] loss: 2.297\n",
            "[5,   500] loss: 2.297\n",
            "[5,  1000] loss: 2.297\n",
            "[5,  1500] loss: 2.297\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CwFZg31DHxtd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f7f96cff-2d8e-4f2e-9545-17e89fae4f11"
      },
      "cell_type": "code",
      "source": [
        "test(mnist_net,testDataLoader)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 1135/10000 (11%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i5w7o2qvHvve",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (5) \n",
        "특징 : 3개의 Layer를 가지는 Neural Network \n",
        "<구성>  \n",
        "Activation Fucntion - Relu \n",
        "\n",
        "Layer 1 - input:28*28 , output : 40\n",
        "\n",
        "Layer 2 - input: 40 output: 30\n",
        "\n",
        "Layer 3 - input: 30 output : 10\n",
        "\n",
        "Cross Entropy Loss  + SGD optimizer "
      ]
    },
    {
      "metadata": {
        "id": "om28DpFSMCWC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc0 = nn.Linear(28*28,40) #Layer 1 \n",
        "        self.fc1 = nn.Linear(40, 30) # Layer 2\n",
        "        self.fc2 = nn.Linear(30, 10) # Layer 3\n",
        "\n",
        "    def forward(self, x):\n",
        "       \n",
        "        x = x.view(-1,28*28)\n",
        "        x = F.relu(self.fc0(x)) # Layer 1\n",
        "        x = F.relu(self.fc1(x)) # Layer 2\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a4_6U9gSMG4I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_net = MNIST_Net().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.SGD(mnist_net.parameters(), lr=0.001) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pIKlsZtjMJG1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_network(mnist_net,optimizer,trainDataLoader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIgSulxqL1F6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (6) \n",
        "특징 : 3개의 Layer를 가지는 Neural Network \n",
        "<구성>  \n",
        "Layer 1 - input:28*28 , output : 40 + Activation Fucntion - Relu \n",
        "\n",
        "Layer 2 - input: 40 output: 30\n",
        "\n",
        "Layer 3 - input: 30 output : 10\n",
        "\n",
        "Cross Entropy Loss  + **Adam** optimizer "
      ]
    },
    {
      "metadata": {
        "id": "cLsGGqXFQ8kU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc0 = nn.Linear(28*28,40) #Layer 1 \n",
        "        self.fc1 = nn.Linear(40, 30) # Layer 2\n",
        "        self.fc2 = nn.Linear(30, 10) # Layer 3\n",
        "\n",
        "    def forward(self, x):\n",
        "       \n",
        "        x = x.view(-1,28*28)\n",
        "        x = F.relu(self.fc0(x)) # Layer 1\n",
        "        x = F.relu(self.fc1(x)) # Layer 2\n",
        "        x = self.fc2(x) # Layer 3 \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbsfE8DsQ829",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_net = MNIST_Net().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n6LY_L-BRK0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_network(mnist_net,optimizer,trainDataLoader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2cXbcBNfRNMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test(mnist_net,testDataLoader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LShT2tAjRbgo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (7) Batch Norm 을 줘 볼까요?\n",
        "특징 : 2개의 Layer를 가지는 Neural Network\n",
        "\n",
        "<구성>  \n",
        "\n",
        "Layer 1 - input:28*28 , output : 40 + Activation Fucntion - Relu + BatchNorm\n",
        "\n",
        "Layer 2 - input: 40 output: 30 + Activation Fucntion - Relu  + BatchNorm\n",
        "\n",
        "Layer 3 - input: 30 output : 10\n",
        "\n",
        "Cross Entropy Loss  + **Adam** optimizer "
      ]
    },
    {
      "metadata": {
        "id": "NrojnT7vRaOj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc0 = nn.Linear(28*28,40) #Layer 1 \n",
        "        self.bn0 = nn.BatchNorm1d(40) #BatchNorm1 \n",
        "        self.fc1 = nn.Linear(40, 30) # Layer 2\n",
        "        self.bn1 = nn.BatchNorm1d(30) #BatchNorm1 \n",
        "        self.fc2 = nn.Linear(30, 10) # Layer 3\n",
        "\n",
        "    def forward(self, x):\n",
        "       \n",
        "        x = x.view(-1,28*28)\n",
        "        x = F.relu(self.bn0(self.fc0(x))) # Layer 1\n",
        "        x = F.relu(self.bn1(self.fc1(x))) # Layer 2\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pTrn0lmMRkxZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_net = MNIST_Net().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TDvcf1LORk5I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "1f9c6c66-4c7e-4ec0-c2b0-c547479be75a"
      },
      "cell_type": "code",
      "source": [
        "train_network(mnist_net,optimizer,trainDataLoader)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 0.816\n",
            "[1,  1000] loss: 0.280\n",
            "[1,  1500] loss: 0.230\n",
            "[2,   500] loss: 0.164\n",
            "[2,  1000] loss: 0.161\n",
            "[2,  1500] loss: 0.155\n",
            "[3,   500] loss: 0.131\n",
            "[3,  1000] loss: 0.123\n",
            "[3,  1500] loss: 0.133\n",
            "[4,   500] loss: 0.110\n",
            "[4,  1000] loss: 0.110\n",
            "[4,  1500] loss: 0.114\n",
            "[5,   500] loss: 0.101\n",
            "[5,  1000] loss: 0.099\n",
            "[5,  1500] loss: 0.099\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FRqo6UHeRp0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "81f8e82e-f753-4c02-af3e-a2cf0e879c6c"
      },
      "cell_type": "code",
      "source": [
        "test(mnist_net,testDataLoader)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 9715/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zezhu4URRs2l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Let's Do it - 성능을 한번 끝까지 높여볼까요~? 마음대로 한번 최고 성능을 찍어봅시다"
      ]
    },
    {
      "metadata": {
        "id": "qst8UvrTWD3v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Diy_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Diy_Net, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc0 = nn.Linear(28*28,392) #Layer 1 \n",
        "        self.bn0 = nn.BatchNorm1d(392) #BatchNorm1 \n",
        "        self.fc1 = nn.Linear(392, 196) # Layer 2\n",
        "        self.bn1 = nn.BatchNorm1d(196) #BatchNorm1 \n",
        "        self.fc2 = nn.Linear(196, 98) # Layer 3\n",
        "        self.bn2 = nn.BatchNorm1d(98) #BatchNorm1 \n",
        "        self.fc3 = nn.Linear(98, 49) # Layer 4\n",
        "        self.bn3 = nn.BatchNorm1d(49) #BatchNorm1 \n",
        "        self.fc4 = nn.Linear(49, 25) # Layer 5\n",
        "        self.bn4 = nn.BatchNorm1d(25) #BatchNorm1 \n",
        "        self.fc5 = nn.Linear(25, 10) # Output Layter\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,28*28)\n",
        "        x = F.relu(self.bn0(self.fc0(x))) # Layer 1\n",
        "        x = F.relu(self.bn1(self.fc1(x))) # Layer 2\n",
        "        x = F.relu(self.bn2(self.fc2(x))) # Layer 3\n",
        "        x = F.relu(self.bn3(self.fc3(x))) # Layer 4\n",
        "        x = F.relu(self.bn4(self.fc4(x))) # Layer 5\n",
        "\n",
        "        x = self.fc5(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lunw6QAeWRV5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### 정답 : 자신을 위해 가능한 보지 말아주세요~"
      ]
    },
    {
      "metadata": {
        "id": "XfknhI1wRt0t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Diy_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Diy_Net, self).__init__()\n",
        "        \n",
        "        self.fc0 = nn.Linear(28*28,16*5*5)\n",
        "        self.bn0 = nn.BatchNorm1d(16*5*5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 84)\n",
        "        self.bn1 = nn.BatchNorm1d(84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = x.view(-1,28*28)\n",
        "        x = F.relu(self.bn0(self.fc0(x)))\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hReLix9jWVtx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### --"
      ]
    },
    {
      "metadata": {
        "id": "4bndPK0MRxT2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "diy_net = Diy_Net().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.Adam(diy_net.parameters(), lr=0.001) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m3DfeBXoR1Ev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "a2703ac9-f4f6-4989-e9cf-9c50d768e3bd"
      },
      "cell_type": "code",
      "source": [
        "train_network(diy_net,optimizer,trainDataLoader)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 0.809\n",
            "[1,  1000] loss: 0.271\n",
            "[1,  1500] loss: 0.210\n",
            "[2,   500] loss: 0.147\n",
            "[2,  1000] loss: 0.139\n",
            "[2,  1500] loss: 0.130\n",
            "[3,   500] loss: 0.094\n",
            "[3,  1000] loss: 0.102\n",
            "[3,  1500] loss: 0.103\n",
            "[4,   500] loss: 0.078\n",
            "[4,  1000] loss: 0.088\n",
            "[4,  1500] loss: 0.084\n",
            "[5,   500] loss: 0.067\n",
            "[5,  1000] loss: 0.065\n",
            "[5,  1500] loss: 0.064\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ARzaGHPDR2t5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f351f855-7748-4dec-ae3a-49c3b3e49642"
      },
      "cell_type": "code",
      "source": [
        "test(diy_net,testDataLoader)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 9794/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pRRSzKppSEOV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Practical Guide Pytorch nn.Sequential \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "x = F.relu(self.bn0(self.fc0(x)))\n",
        "x = F.relu(self.bn1(self.fc1(x)))\n",
        "```\n",
        "너무 복잡하지 않나요?  그냥 x = self.fc(x) 쉽게 해버리면 안 될까요?\n",
        "\n",
        "Solution : nn.Sequential + 자매품 nn.ModuList\n"
      ]
    },
    {
      "metadata": {
        "id": "oFZe4PjESIOn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Diy_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        \n",
        "        layer_list = [] # 이 리스트에 모든 Layer 를 순차적으로 append 해보겠습니다. \n",
        "        layer_list.append(nn.Linear(28*28,40)) #Layer 1 \n",
        "        layer_list.append(nn.BatchNorm1d(40))#BatchNorm1\n",
        "        layer_list.append(nn.ReLU())\n",
        "        '''\n",
        "        layer 2: input dimension: 40, output dimension: 30, batchnorm, relu\n",
        "        layer 3: input dimension: 30, output dimension: 10\n",
        "        '''\n",
        "        self.net  = nn.Sequential(*layer_list) # nn.Sequential 에 layer list를 넘겨 줍니다.\n",
        "    def forward(self, x):\n",
        "       \n",
        "        x = x.view(-1,28*28)\n",
        "        x = self.net(x) # 넣은 순서대로 적용이 됩니다. \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tqMNVZe7MmEX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "     self.fc0 = nn.Linear(28*28,392) #Layer 1 \n",
        "        self.bn0 = nn.BatchNorm1d(392) #BatchNorm1 \n",
        "        self.fc1 = nn.Linear(392, 196) # Layer 2\n",
        "        self.bn1 = nn.BatchNorm1d(196) #BatchNorm1 \n",
        "        self.fc2 = nn.Linear(196, 98) # Layer 3\n",
        "        self.bn2 = nn.BatchNorm1d(98) #BatchNorm1 \n",
        "        self.fc3 = nn.Linear(98, 49) # Layer 4\n",
        "        self.bn3 = nn.BatchNorm1d(49) #BatchNorm1 \n",
        "        self.fc4 = nn.Linear(49, 25) # Layer 5\n",
        "        self.bn4 = nn.BatchNorm1d(25) #BatchNorm1 \n",
        "        self.fc5 = nn.Linear(25, 10) # Output Layter"
      ]
    },
    {
      "metadata": {
        "id": "9v-_AMTKMSYo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Diy_Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Diy_Net, self).__init__()\n",
        "    \n",
        "    layer_list = []\n",
        "    layer_list.append(nn.Linear(28*28, 392)) # layer 1\n",
        "    layer_list.append(nn.BatchNorm1d(392)) #batchNorm1\n",
        "    layer_list.append(nn.ReLU())\n",
        "    \n",
        "    layer_list.append(nn.Linear(392, 196)) #layer2\n",
        "    layer_list.append(nn.BatchNorm1d(196))\n",
        "    layer_list.append(nn.ReLU())\n",
        "    \n",
        "    layer_list.append(nn.Linear(196, 98)) #layer3\n",
        "    layer_list.append(nn.BatchNorm1d(98))\n",
        "    layer_list.append(nn.ReLU())\n",
        "    \n",
        "    layer_list.append(nn.Linear(98, 49)) #layer4\n",
        "    layer_list.append(nn.BatchNorm1d(49))\n",
        "    layer_list.append(nn.ReLU())\n",
        "    \n",
        "    layer_list.append(nn.Linear(49, 25)) #layer5\n",
        "    layer_list.append(nn.BatchNorm1d(25))\n",
        "    layer_list.append(nn.ReLU())\n",
        "    \n",
        "    layer_list.append(nn.Linear(25, 10)) # Output layer\n",
        "    self.net  = nn.Sequential(*layer_list) # nn.Sequential 에 layer list를 넘겨 줍니다.\n",
        "    \n",
        "  def forward(self, x):\n",
        "\n",
        "      x = x.view(-1,28*28)\n",
        "      x = self.net(x) # 넣은 순서대로 적용이 됩니다. \n",
        "      return x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_RKTk9h3WyL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### 정답 : 자신을 위해 가능한 보지 말아주세요~"
      ]
    },
    {
      "metadata": {
        "id": "zl_MABtAWyL2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Diy_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Diy_Net, self).__init__()\n",
        "        \n",
        "        layer_list = [] # 이 리스트에 모든 Layer 를 순차적으로 append 해보겠습니다. \n",
        "        layer_list.append(nn.Linear(28*28,40)) #Layer 1 \n",
        "        layer_list.append(nn.BatchNorm1d(40))#BatchNorm1\n",
        "        layer_list.append(nn.ReLU())\n",
        "        layer_list.append(nn.Linear(40, 30)) # Layer 2\n",
        "        layer_list.append(nn.BatchNorm1d(30)) #BatchNorm1\n",
        "        layer_list.append(nn.ReLU())\n",
        "        layer_list.append(nn.Linear(30, 10)) # Layer 3\n",
        "        self.net  = nn.Sequential(*layer_list) # nn.Sequential 에 layer list를 넘겨 줍니다.\n",
        "    def forward(self, x):\n",
        "       \n",
        "        x = x.view(-1,28*28)\n",
        "        x = self.net(x) # 넣은 순서대로 적용이 됩니다. \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfKiGwitWyL3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### --"
      ]
    },
    {
      "metadata": {
        "id": "aNigMjqDSQ1E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "diy_net = Diy_Net().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.Adam(diy_net.parameters(), lr=0.001) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pcgg26mSrhwD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "6a778bd7-0225-45d7-8deb-50893b2d1d24"
      },
      "cell_type": "code",
      "source": [
        "train_network(diy_net,optimizer,trainDataLoader)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 0.838\n",
            "[1,  1000] loss: 0.277\n",
            "[1,  1500] loss: 0.208\n",
            "[2,   500] loss: 0.139\n",
            "[2,  1000] loss: 0.152\n",
            "[2,  1500] loss: 0.131\n",
            "[3,   500] loss: 0.106\n",
            "[3,  1000] loss: 0.104\n",
            "[3,  1500] loss: 0.098\n",
            "[4,   500] loss: 0.076\n",
            "[4,  1000] loss: 0.089\n",
            "[4,  1500] loss: 0.087\n",
            "[5,   500] loss: 0.060\n",
            "[5,  1000] loss: 0.072\n",
            "[5,  1500] loss: 0.071\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v1v3G3lrSTMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "e72d2e3d-819c-4f15-f3c3-ce46eec9c3e5"
      },
      "cell_type": "code",
      "source": [
        "test(diy_net,testDataLoader)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 9794/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}